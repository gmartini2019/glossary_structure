{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import Levenshtein\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_word = False\n",
    "        self.description = None\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "    \n",
    "    def insert(self, word, description):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                current.children[char] = TrieNode()\n",
    "            current = current.children[char]\n",
    "        current.is_word = True\n",
    "        current.description = description\n",
    "    \n",
    "    def search(self, word):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                return None\n",
    "            current = current.children[char]\n",
    "        if current.is_word:\n",
    "            return current.description\n",
    "        return None\n",
    "    \n",
    "    def fuzzy_search(self, word, cutoff=0.6):\n",
    "        results = difflib.get_close_matches(word, self.words(), n=10, cutoff=cutoff)\n",
    "        return {result: (self.search(result), difflib.SequenceMatcher(None, word, result).ratio()) for result in results}\n",
    "\n",
    "    def fuzzy_search_knn(self, word, k=5, cutoff=0.6):\n",
    "        words = np.array(self.words())\n",
    "        words_len = np.array([len(w) for w in words])\n",
    "        word_len = len(word)\n",
    "        distances = np.abs(words_len - word_len)\n",
    "        knn = NearestNeighbors(n_neighbors=k, metric='manhattan')\n",
    "        knn.fit(distances.reshape(-1, 1))\n",
    "        _, indices = knn.kneighbors(np.array([word_len]).reshape(-1, 1))\n",
    "        results = [words[index] for index in indices[0]]\n",
    "        ratio = [difflib.SequenceMatcher(None, word, result).ratio() for result in results]\n",
    "        return {result: (self.search(result), ratio[i]) for i, result in enumerate(results) if ratio[i] >= cutoff}\n",
    "        \n",
    "        \n",
    "    def words(self):\n",
    "        words = []\n",
    "        def dfs(node, word):\n",
    "            if node.is_word:\n",
    "                words.append(word)\n",
    "            for char in node.children:\n",
    "                dfs(node.children[char], word + char)\n",
    "        dfs(self.root, \"\")\n",
    "        return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie()\n",
    "trie.insert(\"first_name\", \"The first name of a person\")\n",
    "trie.insert(\"last_name\", \"The last name of a person\")\n",
    "trie.insert(\"street\", \"The street where somebody lives\")\n",
    "trie.insert(\"company\", \"enterprise where the employee works\")\n",
    "trie.insert(\"vehicle_type\", \"type of vehicle  the person owns\")\n",
    "trie.insert(\"model\", \"model of the car\")\n",
    "trie.insert(\"date_of_birth\", \"when the person was born\")\n",
    "trie.insert(\"language\", \"which language the person speaks\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first name of a person\n",
      "{}\n",
      "{'last_name': ('The last name of a person', 0.7142857142857143)}\n",
      "{'street': ('The street where somebody lives', 0.8)}\n",
      "{'street': ('The street where somebody lives', 0.6666666666666666)}\n"
     ]
    }
   ],
   "source": [
    "print(trie.search(\"first_name\")) # Output: The first name of a person\n",
    "print(trie.fuzzy_search(\"srt\")) # Output: {'first_name': 'The first name of a person'}\n",
    "print(trie.fuzzy_search(\"lname\"))\n",
    "print(trie.fuzzy_search(\"strt\"))\n",
    "print(trie.fuzzy_search_knn(\"srt\", k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': ('The first name of a person', 0.6666666666666666)}\n",
      "{'first_name': ('The first name of a person', 0.7368421052631579)}\n",
      "{'first_name': ('The first name of a person', 0.6666666666666666)}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(trie.fuzzy_search(\"fname\"))\n",
    "print(trie.fuzzy_search(\"FirstName\"))\n",
    "\n",
    "print(trie.fuzzy_search_knn(\"fname\", k = 1))\n",
    "print(trie.fuzzy_search_knn(\"FirstName\", k = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_name': ('The last name of a person', 0.7142857142857143)}\n",
      "{'last_name': ('The last name of a person', 0.8235294117647058)}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(trie.fuzzy_search(\"lname\"))\n",
    "print(trie.fuzzy_search(\"lastName\"))\n",
    "\n",
    "print(trie.fuzzy_search_knn(\"last_name\", k = 1))\n",
    "print(trie.fuzzy_search_knn(\"lastName\", k = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def build_trie(words):\n",
    "    root = collections.defaultdict(lambda: {\"desc\": None, \"children\": collections.defaultdict(dict)})\n",
    "    for word, desc in words:\n",
    "        node = root\n",
    "        for char in word:\n",
    "            node = node[\"children\"].setdefault(char, collections.defaultdict(dict))\n",
    "        node[\"desc\"] = desc\n",
    "    return root\n",
    "\n",
    "def damerau_levenshtein_distance(a, b, d):\n",
    "    la, lb = len(a), len(b)\n",
    "    da = [0] * (la + 1)\n",
    "    db = [0] * (lb + 1)\n",
    "    for i in range(la + 1):\n",
    "        da[i] = i\n",
    "    for j in range(lb + 1):\n",
    "        db[j] = j\n",
    "    for i in range(1, la + 1):\n",
    "        for j in range(1, lb + 1):\n",
    "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
    "            da[i] = min(da[i - 1] + 1, db[j] + 1, da[i - 1] + cost)\n",
    "            if i > 1 and j > 1 and a[i - 1] == b[j - 2] and a[i - 2] == b[j - 1]:\n",
    "                da[i] = min(da[i], db[j - 2] + cost)\n",
    "            db[j] = da[i]\n",
    "    return da[la]\n",
    "\n",
    "def fuzzy_match(trie, pattern, max_distance):\n",
    "    queue = [(trie, 0, 0, [])]\n",
    "    while queue:\n",
    "        node, i, distance, path = queue.pop(0)\n",
    "        if distance > max_distance:\n",
    "            continue\n",
    "        if \"desc\" in node and node[\"desc\"] is not None:\n",
    "            yield \"\".join(path), node[\"desc\"]\n",
    "        for char, child in node[\"children\"].items():\n",
    "            j = i + 1\n",
    "            if j == len(pattern):\n",
    "                if distance <= max_distance:\n",
    "                    yield char, node[\"desc\"]\n",
    "                continue\n",
    "            if char == pattern[j]:\n",
    "                queue.append((child, j, distance, path + [char]))\n",
    "            else:\n",
    "                d = damerau_levenshtein_distance(char, pattern[j], max_distance)\n",
    "                queue.append((child, j, distance + d, path + [char]))\n",
    "\n",
    "words = [(\"dog\", \"domestic animal\"), (\"doe\", \"female deer\"), (\"cat\", \"domestic animal\"), (\"cot\", \"a bed for camping\")]\n",
    "trie = build_trie(words)\n",
    "for word, desc in fuzzy_match(trie, 'dot', 1):\n",
    "    print(word, \":\", desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_303/3743261917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzzy_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'word'"
     ]
    }
   ],
   "source": [
    "result = fuzzy_match(trie, 'dot', 1)\n",
    "print(result.word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherlockEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57d0fe2675c1864a6211176a164e0da308406f51aa8b24d41036509a8cf66bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
