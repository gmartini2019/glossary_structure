{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "import Levenshtein\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.is_word = False\n",
    "        self.description = None\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "    \n",
    "    def insert(self, word, description):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            current = current.children[char]\n",
    "        current.is_word = True\n",
    "        current.description = description\n",
    "    \n",
    "    def search(self, word):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                return None\n",
    "            current = current.children[char]\n",
    "        if current.is_word:\n",
    "            return current.description\n",
    "        return None\n",
    "    \n",
    "    def fuzzy_search(self, word, cutoff=0.4):\n",
    "        results = difflib.get_close_matches(word, self.words(), n=10, cutoff=cutoff)\n",
    "        return {result: (self.search(result), difflib.SequenceMatcher(None, word, result).ratio()) for result in results}\n",
    "\n",
    "    def fuzzy_search_knn(self, word, k=5, cutoff=0.6):\n",
    "        words = np.array(self.words())\n",
    "        words_len = np.array([len(w) for w in words])\n",
    "        word_len = len(word)\n",
    "        distances = np.abs(words_len - word_len)\n",
    "        knn = NearestNeighbors(n_neighbors=k, metric='manhattan')\n",
    "        knn.fit(distances.reshape(-1, 1))\n",
    "        _, indices = knn.kneighbors(np.array([word_len]).reshape(-1, 1))\n",
    "        results = [words[index] for index in indices[0]]\n",
    "        ratio = [difflib.SequenceMatcher(None, word, result).ratio() for result in results]\n",
    "        return {result: (self.search(result), ratio[i]) for i, result in enumerate(results) if ratio[i] >= cutoff}\n",
    "        \n",
    "        \n",
    "    def words(self):\n",
    "        words = []\n",
    "        def dfs(node, word):\n",
    "            if node.is_word:\n",
    "                words.append(word)\n",
    "            for char in node.children:\n",
    "                dfs(node.children[char], word + char)\n",
    "        dfs(self.root, \"\")\n",
    "        return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie()\n",
    "trie.insert(\"first_name\", \"The first name of a person\")\n",
    "trie.insert(\"last_name\", \"The last name of a person\")\n",
    "trie.insert(\"street\", \"The street where somebody lives\")\n",
    "trie.insert(\"company\", \"enterprise where the employee works\")\n",
    "trie.insert(\"vehicle_type\", \"type of vehicle  the person owns\")\n",
    "trie.insert(\"model\", \"model of the car\")\n",
    "trie.insert(\"date_of_birth\", \"when the person was born\")\n",
    "trie.insert(\"language\", \"which language the person speaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first name of a person\n",
      "{'street': ('The street where somebody lives', 0.6666666666666666)}\n",
      "{'model': ('model of the car', 0.5454545454545454), 'last_name': ('The last name of a person', 0.5333333333333333), 'first_name': ('The first name of a person', 0.5)}\n",
      "{'street': ('The street where somebody lives', 0.8)}\n",
      "{'street': ('The street where somebody lives', 0.6666666666666666)}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trie.search(\"first_name\")) # Output: The first name of a person\n",
    "print(trie.fuzzy_search(\"srt\")) # Output: {'first_name': 'The first name of a person'}\n",
    "print(trie.fuzzy_search(\"name_l\"))\n",
    "print(trie.fuzzy_search(\"strt\"))\n",
    "print(trie.fuzzy_search_knn(\"srt\", k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': ('The first name of a person', 0.6666666666666666)}\n",
      "{'first_name': ('The first name of a person', 0.7368421052631579)}\n",
      "{'first_name': ('The first name of a person', 0.6666666666666666)}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(trie.fuzzy_search(\"fname\"))\n",
    "print(trie.fuzzy_search(\"FirstName\"))\n",
    "\n",
    "print(trie.fuzzy_search_knn(\"fname\", k = 1))\n",
    "print(trie.fuzzy_search_knn(\"FirstName\", k = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_name': ('The last name of a person', 0.7142857142857143)}\n",
      "{'last_name': ('The last name of a person', 0.8235294117647058)}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(trie.fuzzy_search(\"lname\"))\n",
    "print(trie.fuzzy_search(\"lastName\"))\n",
    "\n",
    "print(trie.fuzzy_search_knn(\"last_name\", k = 1))\n",
    "print(trie.fuzzy_search_knn(\"lastName\", k = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trie(words):\n",
    "    root = defaultdict(lambda: {\"desc\": None, \"children\": defaultdict(dict)})\n",
    "    for word, desc in words:\n",
    "        node = root\n",
    "        for char in word:\n",
    "            node = node[\"children\"].setdefault(char, defaultdict(dict))\n",
    "        node[\"desc\"] = desc\n",
    "    return root\n",
    "\n",
    "def damerau_levenshtein_distance(a, b, d):\n",
    "    la, lb = len(a), len(b)\n",
    "    da = [0] * (la + 1)\n",
    "    db = [0] * (lb + 1)\n",
    "    for i in range(la + 1):\n",
    "        da[i] = i\n",
    "    for j in range(lb + 1):\n",
    "        db[j] = j\n",
    "    for i in range(1, la + 1):\n",
    "        for j in range(1, lb + 1):\n",
    "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
    "            da[i] = min(da[i - 1] + 1, db[j] + 1, da[i - 1] + cost)\n",
    "            if i > 1 and j > 1 and a[i - 1] == b[j - 2] and a[i - 2] == b[j - 1]:\n",
    "                da[i] = min(da[i], db[j - 2] + cost)\n",
    "            db[j] = da[i]\n",
    "    return da[la]\n",
    "\n",
    "def fuzzy_match(trie, pattern, max_distance):\n",
    "    queue = deque()\n",
    "    queue.append([trie, 0, 0, []])\n",
    "    while queue:\n",
    "        node, i, distance, path = queue.popleft()\n",
    "        if distance > max_distance:\n",
    "            continue\n",
    "        if \"desc\" in node and node[\"desc\"] is not None:\n",
    "            yield \"\".join(path), node[\"desc\"]\n",
    "        for char, child in node[\"children\"].items():\n",
    "            j = i + 1\n",
    "            if j == len(pattern):\n",
    "                if distance <= max_distance:\n",
    "                    yield char, node[\"desc\"]\n",
    "                continue\n",
    "            if char == pattern[j]:\n",
    "                queue.append((child, j, distance, path + [char]))\n",
    "            else:\n",
    "                d = damerau_levenshtein_distance(char, pattern[j], max_distance)\n",
    "                queue.append([child, j, distance + d, path + [char]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = [(\"dog\", \"domestic animal\"), (\"doe\", \"female deer\"), (\"cat\", \"domestic animal\"), (\"cot\", \"a bed for camping\")]\n",
    "trie = build_trie(words)\n",
    "for word, desc in fuzzy_match(trie, 'dot', 1):\n",
    "    print(word, \":\", desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object fuzzy_match at 0x1415f4580>\n"
     ]
    }
   ],
   "source": [
    "result = fuzzy_match(trie, 'dot', 1)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherlockEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57d0fe2675c1864a6211176a164e0da308406f51aa8b24d41036509a8cf66bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
