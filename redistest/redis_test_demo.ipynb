{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import redis\n",
    "import csv\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import difflib\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import tensorflow\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../englishwords.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "words = data.keys()\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode_dict:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode_dict)\n",
    "        self.is_word = False\n",
    "        self.description = None\n",
    "        \n",
    "\n",
    "class Trie_dict:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode_dict()\n",
    "        self.count = 0\n",
    "        \n",
    "    def insert(self, word, description=None):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            current = current.children[char]\n",
    "        if not current.is_word:\n",
    "            current.is_word = True\n",
    "            self.count += 1\n",
    "        current.description = description\n",
    "    \n",
    "    def search(self, word):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                return None\n",
    "            current = current.children[char]\n",
    "        if current.is_word:\n",
    "            return current.description\n",
    "        return None\n",
    "\n",
    "    def insert_list(self, lst):\n",
    "        for word in lst:\n",
    "            self.insert(word) \n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "    \n",
    "    \n",
    "    def insert_dict(self, dict_obj):\n",
    "        for key, definition in dict_obj.items():\n",
    "            self.insert(key, definition)\n",
    "\n",
    "    \n",
    "    def fuzzy_search(self, word, cutoff=0.6):\n",
    "        results = difflib.get_close_matches(word, self.words(), n=10, cutoff=cutoff)\n",
    "        return {result: (self.search(result), difflib.SequenceMatcher(None, word, result).ratio()) for result in results}\n",
    "        \n",
    "    def words(self):\n",
    "        words = []\n",
    "        def dfs(node, word):\n",
    "            if node.is_word:\n",
    "                words.append(word)\n",
    "            for char in node.children:\n",
    "                dfs(node.children[char], word + char)\n",
    "        dfs(self.root, \"\")\n",
    "        return words\n",
    "\n",
    "#trie_dict.insert_list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/lingechettyr/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lingechettyr/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lingechettyr/nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lingechettyr/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lingechettyr/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wordcloud\n",
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function\n",
    "dict_obj = defaultdict()\n",
    "\n",
    "def get_definition(word):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    return synsets[0].definition() if synsets else None\n",
    "  \n",
    "for i in range(len(words)):\n",
    "  definition = get_definition(words[i])\n",
    "  if definition != None:\n",
    "    dict_obj[words[i]] = definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the area or vicinity'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_obj['around']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../english_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../english_dict.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trying something to find out about it'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test = Trie_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.insert_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': ('on the move', 1.0),\n",
       " 'bout': ('(sports) a division during which one team is on the offensive',\n",
       "  0.8888888888888888),\n",
       " 'abut': ('lie adjacent to another or share a boundary', 0.8888888888888888),\n",
       " 'abought': ('make amends for', 0.8333333333333334),\n",
       " 'sabot': ('a shoe carved from a single block of wood', 0.8),\n",
       " 'jabot': (\"a ruffle on the front of a woman's blouse or a man's shirt\", 0.8),\n",
       " 'cabot': ('son of John Cabot who was born in Italy and who led an English expedition in search of the Northwest Passage and a Spanish expedition that explored the La Plata region of Brazil; in 1544 he published a map of the world (1476-1557)',\n",
       "  0.8),\n",
       " 'bouts': ('(sports) a division during which one team is on the offensive',\n",
       "  0.8),\n",
       " 'abuts': ('lie adjacent to another or share a boundary', 0.8),\n",
       " 'abort': ('the act of terminating a project or procedure before it is completed',\n",
       "  0.8)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_dict_test.fuzzy_search(\"about\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_time(df, r):\n",
    "    start = time.time()\n",
    "    r.set(\"key\", msgpack.packb(df.to_dict('records')))\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "        \n",
    "    print({'message': f'Data stored successfully. Time elapsed: {elapsed} seconds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Data stored successfully. Time elapsed: 0.0010979175567626953 seconds'}\n",
      "{'message': 'Data stored successfully. Time elapsed: 0.004744529724121094 seconds'}\n",
      "{'message': 'Data stored successfully. Time elapsed: 0.03921985626220703 seconds'}\n",
      "{'message': 'Data stored successfully. Time elapsed: 0.12122011184692383 seconds'}\n",
      "{'message': 'Data stored successfully. Time elapsed: 0.20700693130493164 seconds'}\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'vasu_df.csv'\n",
    "    \n",
    "    # Read data from CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "df_fifty_lines = df.sample(n = 50)\n",
    "df_1000_lines = df.sample(n = 1000)\n",
    "df_10000_lines = df.sample(n  =10000)\n",
    "df_30000_lines = df.sample(n = 30000)\n",
    "    \n",
    "    # Store data in Redis\n",
    "r = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "\n",
    "take_time(df_fifty_lines, r)\n",
    "take_time(df_1000_lines, r)\n",
    "take_time(df_10000_lines, r)\n",
    "take_time(df_30000_lines, r)\n",
    "take_time(df, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trie_from_redis(redis_host='localhost', redis_port=6379, redis_db=0):\n",
    "    r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)\n",
    "    trie = Trie_dict()\n",
    "    keys = r.keys()\n",
    "    for key in keys:\n",
    "        word = key.decode('utf-8')\n",
    "        try:\n",
    "            description = r.get(word).decode('utf-8')\n",
    "        except UnicodeDecodeError as e:\n",
    "            description = 'Could not decode it'\n",
    "        trie.insert(word, description)\n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to store 112272 in Redis: 12.711305141448975\n",
      "Time it took to retrieve 112278 in Redis: 13.978270530700684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def store_in_redis(trie_dict, r, redis_host='localhost', redis_port=6379, redis_db=0):\n",
    "    for word in trie_dict.words():\n",
    "        description = trie_dict.search(word)\n",
    "        r.set(word, description)\n",
    "\n",
    "def get_trie_from_redis(redis_host='localhost', redis_port=6379, redis_db=0):\n",
    "    r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)\n",
    "    trie = Trie_dict()\n",
    "    keys = r.keys()\n",
    "    for key in keys:\n",
    "        word = key.decode('utf-8')\n",
    "        try:\n",
    "            description = r.get(word).decode('utf-8')\n",
    "        except UnicodeDecodeError as e:\n",
    "            description = 'Could not decode it'\n",
    "        trie.insert(word, description)\n",
    "    return trie\n",
    "start_time_store = time.time()\n",
    "store_in_redis(trie_dict, r)\n",
    "end_time_store = time.time()\n",
    "store_time = end_time_store - start_time_store\n",
    "\n",
    "start_time_get = time.time()\n",
    "trie_dict2 = get_trie_from_redis()\n",
    "end_time_get = time.time()\n",
    "get_time = end_time_get - start_time_get\n",
    "\n",
    "print(f'Time it took to store {trie_dict.size()} in Redis: {store_time}')\n",
    "print(f'Time it took to retrieve {trie_dict2.size()} in Redis: {get_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa5 in position 14: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5835/1529246571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time_get\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrie_dict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trie_from_redis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend_time_get\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time_get\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5835/2076487945.py\u001b[0m in \u001b[0;36mget_trie_from_redis\u001b[0;34m(redis_host, redis_port, redis_db)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa5 in position 14: invalid start byte"
     ]
    }
   ],
   "source": [
    "start_time_get = time.time()\n",
    "trie_dict2 = get_trie_from_redis()\n",
    "end_time_get = time.time()\n",
    "get_time = end_time_get - start_time_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_df_to_dict(df):\n",
    "    first_column = df.iloc[:, 0].tolist()\n",
    "    second_column = df.iloc[:, 1].tolist()\n",
    "    dict_object = my_dictionary()\n",
    "    for i in range(len(first_column)):\n",
    "        dict_object.add(first_column[i], second_column[i])\n",
    "    \n",
    "    return dict_object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def tokenizerImport(self):\n",
    "        with open('tokenizer.json') as f:\n",
    "            data = json.load(f)\n",
    "            tokenizer = tokenizer_from_json(data)\n",
    "        return tokenizer\n",
    "    \n",
    "    def modelImport(self):\n",
    "        model = load_model('model_general_1.h5')\n",
    "        return model\n",
    "        \n",
    "    def build_definition(self, seed_text, tokenizer, next_words, model, max_sequence_len):\n",
    "        res = []\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "            predicted = model.predict(token_list)\n",
    "            predicted = np.argmax(predicted, axis = 1)\n",
    "            \n",
    "            output_word = \"\"\n",
    "            for word,index in tokenizer.word_index.items():\n",
    "                if index == predicted:\n",
    "                    output_word = word\n",
    "                    break\n",
    "            res.append(output_word)\n",
    "            seed_text += \" \" + output_word\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_trie(trie_dict):\n",
    "    # ML_used = False\n",
    "    # Prompt the user to enter a search term\n",
    "    print('Enter the term for which you would like the definition')\n",
    "    search = input()\n",
    "    \n",
    "    # Use the trie data structure to perform a fuzzy search on the search term\n",
    "    search_result = list(trie_dict.fuzzy_search(search))\n",
    "    list_length = len(search_result)\n",
    "    \n",
    "    # If the search term is not found in the trie, prompt the user to define it\n",
    "    if list_length == 0:\n",
    "        print('It is not in our list, please define it yourself')\n",
    "        definition = input()\n",
    "        #fine_tune(search, definition)\n",
    "        print(f\"Thanks, I've learned the definition of '{search}'.\")\n",
    "        \n",
    "    # If the search term is found in the trie, present the user with a list of search results\n",
    "    else:\n",
    "        for i, item in enumerate(search_result):\n",
    "            print(f\"{i+1}. {item}\")\n",
    "        \n",
    "        # Prompt the user to select a search result from the list\n",
    "        print('If the desired item is in the list, type Y')\n",
    "        choice = input()\n",
    "        if choice == 'Y':\n",
    "            print('Now type the number associated to the desired term')\n",
    "            user_choice = int(input())\n",
    "            \n",
    "            # Ensure that the user's choice is a valid index in the list of search results\n",
    "            1 <= user_choice <= len(search_result)\n",
    "            selected_item = search_result[user_choice - 1]\n",
    "            print(f\"You selected: {selected_item}\")\n",
    "            \n",
    "            # Look up the definition of the selected term in the trie data structure\n",
    "            word_definition = trie_dict.search(selected_item)\n",
    "            \n",
    "            # If the term has no definition in the trie, prompt the user to define it\n",
    "            if word_definition == None:\n",
    "                print(f'No previous definition has been found, however {selected_item} is commonly referred to as:\\n ')\n",
    "                print(get_definition(selected_item))\n",
    "                print('Now you can define it yourself')\n",
    "                custom_definition = input()\n",
    "                trie_dict.insert(selected_item, custom_definition)\n",
    "                print('Thank you, I learned a new word!')\n",
    "            \n",
    "            # If the term has a definition in the trie, present the definition to the user and prompt for redefinition\n",
    "            else:\n",
    "                print(f'The definition for {selected_item} is : {word_definition}')\n",
    "                print(f'Do you like it? Type \"Y\" if so, if not you\"ll redefine it')\n",
    "                redefinition_choice = input()\n",
    "                \n",
    "                # If the user chooses to redefine the term, prompt for a new definition and update the trie\n",
    "                if redefinition_choice != 'Y':\n",
    "                    print('Type it in:')\n",
    "                    custom_definition = input()\n",
    "                    trie_dict.insert(selected_item, custom_definition)\n",
    "                    print('Thank you, I learned a new word!')\n",
    "        else:\n",
    "            print(f'Run ML model? (Type \"Y\" for yes and \"N\" for no)')\n",
    "            runChoice = input()\n",
    "            if runChoice == \"Y\":\n",
    "                print(f'\"{search}\" is not in the list, running ML model to generate definition')\n",
    "                ml_model = MLModel()\n",
    "                tokenizer = ml_model.tokenizerImport()\n",
    "                model = ml_model.modelImport()\n",
    "                res = ml_model.build_definition(search, tokenizer, 5, model, 54)\n",
    "                \n",
    "                for i in range(len(res)):\n",
    "                    print(f\"{i+1}. {res[i]}\")\n",
    "                \n",
    "                print(f'If you see a definition that you are satisfied with, select the corresponding number - else if you are not satisifed with any option, type \"N\": ')\n",
    "                mlChoice = input()\n",
    "\n",
    "                if mlChoice != 'N':\n",
    "                    trie_dict.insert(search, res[int(mlChoice)])\n",
    "                else:\n",
    "                    print('Add your own definition: ')\n",
    "                    definition_nbs = input()\n",
    "                    trie_dict.insert(search, definition_nbs)\n",
    "            else:\n",
    "                print('Add your own definition: ')\n",
    "                definition_nbs = input()\n",
    "                trie_dict.insert(search, definition_nbs)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGINNING OF DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_demo = Trie_dict()\n",
    "connection = redis.Redis(host='localhost', port=6379, db=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vasu's SAP data is imported in the notebook, and fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'vasu_df.csv'\n",
    "# Read data from CSV\n",
    "df_vasu = pd.read_csv(csv_file)\n",
    "#Transform it into a dictionary\n",
    "dictionary_vasu = from_df_to_dict(df_vasu)\n",
    "#Load it to the trie tree\n",
    "for key in dictionary_vasu.keys():\n",
    "    definition = str(dictionary_vasu[key])\n",
    "    trie_demo.insert(str(key), definition)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trie tree is loaded, time to search some elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Work Incapacity Notification for Joint Admin. Office (GAK)?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple search of a term we KNOW is present\n",
    "trie_demo.search('AAO_GAK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAO_GAK': ('Work Incapacity Notification for Joint Admin. Office (GAK)?',\n",
       "  0.8)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fuzzy search of a term that RESEMBLES a term present in the structure\n",
    "trie_demo.fuzzy_search('AAO_GrK\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'Navigate' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the term for which you would like the definition\n",
      "1. AAO_GQL\n",
      "2. AAO_GAK\n",
      "3. VALTO_AGL\n",
      "4. CATCA_QAL\n",
      "If the desired item is in the list, type Y\n",
      "Now type the number associated to the desired term\n",
      "You selected: VALTO_AGL\n",
      "The definition for VALTO_AGL is : Date Up to Which the Contents of the Agreement Are Valid\n",
      "Do you like it? Type \"Y\" if so, if not you\"ll redefine it\n"
     ]
    }
   ],
   "source": [
    "#Function where everything goes according to plan \n",
    "navigate_trie(trie_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the term for which you would like the definition\n",
      "1. AAO_GQL\n",
      "2. OSL_S\n",
      "3. NO_SLOTS\n",
      "4. DATAOBJ_CLS\n",
      "5. BAS_SALS\n",
      "6. AVG_SALS\n",
      "7. AUTO_POSS\n",
      "8. OS_SYS\n",
      "If the desired item is in the list, type Y\n",
      "Now type the number associated to the desired term\n",
      "You selected: DATAOBJ_CLS\n",
      "The definition for DATAOBJ_CLS is : Data object class\n",
      "Do you like it? Type \"Y\" if so, if not you\"ll redefine it\n",
      "Type it in:\n",
      "Thank you, I learned a new word!\n"
     ]
    }
   ],
   "source": [
    "#Function where the user does not like the definition provided by the structure\n",
    "navigate_trie(trie_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a definition I like better'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_demo.search('DATAOBJ_CLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the term for which you would like the definition\n",
      "1. WID\n",
      "2. WPID\n",
      "3. WGID\n",
      "If the desired item is in the list, type Y\n",
      "\"WIDJDW\" is not in the list, add it to the database!\n",
      "Add a definition:\n"
     ]
    }
   ],
   "source": [
    "#Scenario where the term we are looking for simply isn't in  the structure\n",
    "navigate_trie(trie_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just made this up'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And here it is, added to the structure\n",
    "trie_demo.search('WIDJDW')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The trie structure is then loaded into a Redis server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "store_in_redis(trie_demo, r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And can also be taken out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just made this up'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_demo2 = get_trie_from_redis()\n",
    "trie_demo2.search('WIDJDW')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9b4a2bb493eda419a542eae9e195fcc22a0fd830f7d7e5d4eaaa6ec7ed188b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
