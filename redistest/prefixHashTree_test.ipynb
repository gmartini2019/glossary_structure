{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import redis\n",
    "import csv\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import difflib\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import tensorflow\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode_dict:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode_dict)\n",
    "        self.is_word = False\n",
    "        self.description = None\n",
    "        \n",
    "\n",
    "class Trie_dict:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode_dict()\n",
    "        self.count = 0\n",
    "        \n",
    "    def insert(self, word, description=None):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            current = current.children[char]\n",
    "        if not current.is_word:\n",
    "            current.is_word = True\n",
    "            self.count += 1\n",
    "        current.description = description\n",
    "    \n",
    "    def search(self, word):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                return None\n",
    "            current = current.children[char]\n",
    "        if current.is_word:\n",
    "            return current.description\n",
    "        return None\n",
    "\n",
    "    def insert_list(self, lst):\n",
    "        for word in lst:\n",
    "            self.insert(word) \n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "    \n",
    "    def insert_dict(self, dict_obj):\n",
    "        for key, definition in dict_obj.items():\n",
    "            self.insert(key, definition)\n",
    "    \n",
    "    def fuzzy_search(self, word, cutoff=0.6):\n",
    "        results = difflib.get_close_matches(word, self.words(), n=10, cutoff=cutoff)\n",
    "        return {result: (self.search(result), difflib.SequenceMatcher(None, word, result).ratio()) for result in results}\n",
    "        \n",
    "    def words(self):\n",
    "        words = []\n",
    "        def dfs(node, word):\n",
    "            if node.is_word:\n",
    "                words.append(word)\n",
    "            for char in node.children:\n",
    "                dfs(node.children[char], word + char)\n",
    "        dfs(self.root, \"\")\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../english_dict.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test = Trie_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.insert(\"best\", \"TEST1\")\n",
    "trie_dict_test.insert(\"beer\", \"TEST2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('b', <__main__.TrieNode_dict object at 0x2981fd480>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_dict_test.root.children.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.insert_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.fuzzy_search(\"bes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trie_to_prefix_hash(trie):\n",
    "    prefix_hash = defaultdict(dict)\n",
    "    queue = [(trie.root, '')]\n",
    "    while queue:\n",
    "        node, prefix = queue.pop(0)\n",
    "        if node.is_word == True:\n",
    "            prefix_hash[prefix][prefix] = node.description\n",
    "        for char, child_node in node.children.items():\n",
    "            child_prefix = prefix + char\n",
    "            prefix_hash[prefix][child_prefix] = child_node.description\n",
    "            queue.append((child_node, child_prefix))\n",
    "    return prefix_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_prefix(trie):\n",
    "    result = {}\n",
    "    def dfs(node, prefix):\n",
    "        if node.is_word:\n",
    "            result[prefix] = [(prefix, node.description)]\n",
    "        for child_key in node.children:\n",
    "            child_node = node.children[child_key]\n",
    "            dfs(child_node, prefix + child_key)\n",
    "        if node.is_word and prefix in result:\n",
    "            result[prefix].append((prefix, node.description))\n",
    "    dfs(trie.root, \"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefHashTree = trie_to_prefix_hash(trie_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefHashTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_trie_to_redis(trie):\n",
    "    def dfs(node, node_key):\n",
    "        for child_key in node.children:\n",
    "            child_node = node.children[child_key]\n",
    "            child_key = node_key + child_key\n",
    "            child_node_key = f\"{child_key}:node\"\n",
    "            r.hset(child_node_key, \"is_word\", str(child_node.is_word))\n",
    "            r.hset(child_node_key, \"description\", child_node.description)\n",
    "            if child_node.is_word:\n",
    "                r.hset(child_node_key, \"word\", child_key)\n",
    "            dfs(child_node, child_key)\n",
    "    dfs(trie.root, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_trie_to_redis(trie_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def tokenizerImport(self):\n",
    "        with open('tokenizer.json') as f:\n",
    "            data = json.load(f)\n",
    "            tokenizer = tokenizer_from_json(data)\n",
    "        return tokenizer\n",
    "    \n",
    "    def modelImport(self):\n",
    "        model = load_model('model_general_1.h5')\n",
    "        return model\n",
    "        \n",
    "    def build_definition(self, seed_text, tokenizer, next_words, model, max_sequence_len):\n",
    "        res = []\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "            predicted = model.predict(token_list)\n",
    "            predicted = np.argmax(predicted, axis = 1)\n",
    "            \n",
    "            output_word = \"\"\n",
    "            for word,index in tokenizer.word_index.items():\n",
    "                if index == predicted:\n",
    "                    output_word = word\n",
    "                    break\n",
    "            res.append(output_word)\n",
    "            seed_text += \" \" + output_word\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_trie(trie_dict):\n",
    "    # ML_used = False\n",
    "    # Prompt the user to enter a search term\n",
    "    print('Enter the term for which you would like the definition')\n",
    "    search = input()\n",
    "    \n",
    "    # Use the trie data structure to perform a fuzzy search on the search term\n",
    "    search_result = list(trie_dict.fuzzy_search(search))\n",
    "    list_length = len(search_result)\n",
    "    \n",
    "    # If the search term is not found in the trie, prompt the user to define it\n",
    "    if list_length == 0:\n",
    "        print('It is not in our list, please define it yourself')\n",
    "        definition = input()\n",
    "        #fine_tune(search, definition)\n",
    "        print(f\"Thanks, I've learned the definition of '{search}'.\")\n",
    "        \n",
    "    # If the search term is found in the trie, present the user with a list of search results\n",
    "    else:\n",
    "        for i, item in enumerate(search_result):\n",
    "            print(f\"{i+1}. {item}\")\n",
    "        \n",
    "        # Prompt the user to select a search result from the list\n",
    "        print('If the desired item is in the list, type Y')\n",
    "        choice = input()\n",
    "        if choice == 'Y':\n",
    "            print('Now type the number associated to the desired term')\n",
    "            user_choice = int(input())\n",
    "            \n",
    "            # Ensure that the user's choice is a valid index in the list of search results\n",
    "            1 <= user_choice <= len(search_result)\n",
    "            selected_item = search_result[user_choice - 1]\n",
    "            print(f\"You selected: {selected_item}\")\n",
    "            \n",
    "            # Look up the definition of the selected term in the trie data structure\n",
    "            word_definition = trie_dict.search(selected_item)\n",
    "            \n",
    "            # If the term has no definition in the trie, prompt the user to define it\n",
    "            if word_definition == None:\n",
    "                print(f'No previous definition has been found, however {selected_item} is commonly referred to as:\\n ')\n",
    "                print(get_definition(selected_item))\n",
    "                print('Now you can define it yourself')\n",
    "                custom_definition = input()\n",
    "                trie_dict.insert(selected_item, custom_definition)\n",
    "                print('Thank you, I learned a new word!')\n",
    "            \n",
    "            # If the term has a definition in the trie, present the definition to the user and prompt for redefinition\n",
    "            else:\n",
    "                print(f'The definition for {selected_item} is : {word_definition}')\n",
    "                print(f'Do you like it? Type \"Y\" if so, if not you\"ll redefine it')\n",
    "                redefinition_choice = input()\n",
    "                \n",
    "                # If the user chooses to redefine the term, prompt for a new definition and update the trie\n",
    "                if redefinition_choice != 'Y':\n",
    "                    print('Type it in:')\n",
    "                    custom_definition = input()\n",
    "                    trie_dict.insert(selected_item, custom_definition)\n",
    "                    print('Thank you, I learned a new word!')\n",
    "        else:\n",
    "            print(f'Run ML model? (Type \"Y\" for yes and \"N\" for no)')\n",
    "            runChoice = input()\n",
    "            if runChoice == \"Y\":\n",
    "                print(f'\"{search}\" is not in the list, running ML model to generate definition')\n",
    "                ml_model = MLModel()\n",
    "                tokenizer = ml_model.tokenizerImport()\n",
    "                model = ml_model.modelImport()\n",
    "                res = ml_model.build_definition(search, tokenizer, 5, model, 54)\n",
    "                \n",
    "                for i in range(len(res)):\n",
    "                    print(f\"{i+1}. {res[i]}\")\n",
    "                \n",
    "                print(f'If you see a definition that you are satisfied with, select the corresponding number - else if you are not satisifed with any option, type \"N\": ')\n",
    "                mlChoice = input()\n",
    "\n",
    "                if mlChoice != 'N':\n",
    "                    trie_dict.insert(search, res[int(mlChoice)])\n",
    "                else:\n",
    "                    print('Add your own definition: ')\n",
    "                    definition_nbs = input()\n",
    "                    trie_dict.insert(search, definition_nbs)\n",
    "            else:\n",
    "                print('Add your own definition: ')\n",
    "                definition_nbs = input()\n",
    "                trie_dict.insert(search, definition_nbs)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9b4a2bb493eda419a542eae9e195fcc22a0fd830f7d7e5d4eaaa6ec7ed188b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
