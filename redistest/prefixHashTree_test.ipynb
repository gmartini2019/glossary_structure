{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import redis\n",
    "import csv\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import difflib\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import tensorflow\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode_dict:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode_dict)\n",
    "        self.is_word = False\n",
    "        self.description = None\n",
    "        \n",
    "\n",
    "class Trie_dict:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode_dict()\n",
    "        self.count = 0\n",
    "        \n",
    "    def insert(self, word, description=None):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            current = current.children[char]\n",
    "        if not current.is_word:\n",
    "            current.is_word = True\n",
    "            self.count += 1\n",
    "        current.description = description\n",
    "    \n",
    "    def search(self, word):\n",
    "        current = self.root\n",
    "        for char in word:\n",
    "            if char not in current.children:\n",
    "                return None\n",
    "            current = current.children[char]\n",
    "        if current.is_word:\n",
    "            return current.description\n",
    "        return None\n",
    "\n",
    "    def insert_list(self, lst):\n",
    "        for word in lst:\n",
    "            self.insert(word) \n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "    \n",
    "    def insert_dict(self, dict_obj):\n",
    "        for key, definition in dict_obj.items():\n",
    "            self.insert(key, definition)\n",
    "    \n",
    "    def fuzzy_search(self, word, cutoff=0.6):\n",
    "        results = difflib.get_close_matches(word, self.words(), n=10, cutoff=cutoff)\n",
    "        return {result: (self.search(result), difflib.SequenceMatcher(None, word, result).ratio()) for result in results}\n",
    "        \n",
    "    def words(self):\n",
    "        words = []\n",
    "        def dfs(node, word):\n",
    "            if node.is_word:\n",
    "                words.append(word)\n",
    "            for char in node.children:\n",
    "                dfs(node.children[char], word + char)\n",
    "        dfs(self.root, \"\")\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../english_dict.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trying something to find out about it'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test = Trie_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.insert(\"best\", \"TEST1\")\n",
    "trie_dict_test.insert(\"beer\", \"TEST2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_dict_test.insert_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best': ('TEST1', 0.8571428571428571)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_dict_test.fuzzy_search(\"bes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trie_to_prefix_hash(trie):\n",
    "    prefix_hash = defaultdict(dict)\n",
    "    queue = [(trie.root, '')]\n",
    "    while queue:\n",
    "        node, prefix = queue.pop(0)\n",
    "        if node.is_word == True:\n",
    "            prefix_hash[prefix][prefix] = node.description\n",
    "        for char, child_node in node.children.items():\n",
    "            child_prefix = prefix + char\n",
    "            prefix_hash[prefix][child_prefix] = child_node.description\n",
    "            queue.append((child_node, child_prefix))\n",
    "    return prefix_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_prefix(trie):\n",
    "    result = {}\n",
    "    def dfs(node, prefix):\n",
    "        if node.is_word:\n",
    "            result[prefix] = [(prefix, node.description)]\n",
    "        for child_key in node.children:\n",
    "            child_node = node.children[child_key]\n",
    "            dfs(child_node, prefix + child_key)\n",
    "        if node.is_word and prefix in result:\n",
    "            result[prefix].append((prefix, node.description))\n",
    "    dfs(trie.root, \"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefHashTree = trie_to_prefix_hash(trie_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'': {'b': None},\n",
       "             'b': {'be': None},\n",
       "             'be': {'bes': None, 'bee': None},\n",
       "             'bes': {'best': 'TEST1'},\n",
       "             'bee': {'beer': 'TEST2'},\n",
       "             'best': {'best': 'TEST1'},\n",
       "             'beer': {'beer': 'TEST2'}})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefHashTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_trie_to_redis(trie):\n",
    "    def dfs(node, node_key):\n",
    "        for child_key in node.children:\n",
    "            child_node = node.children[child_key]\n",
    "            child_key = node_key + child_key\n",
    "            child_node_key = f\"{child_key}:node\"\n",
    "            r.hset(child_node_key, \"is_word\", str(child_node.is_word))\n",
    "            r.hset(child_node_key, \"description\", child_node.description)\n",
    "            if child_node.is_word:\n",
    "                r.hset(child_node_key, \"word\", child_key)\n",
    "            dfs(child_node, child_key)\n",
    "    dfs(trie.root, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "Invalid input of type: 'NoneType'. Convert to a bytes, string, int or float first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m import_trie_to_redis(trie_dict_test)\n",
      "Cell \u001b[0;32mIn[126], line 12\u001b[0m, in \u001b[0;36mimport_trie_to_redis\u001b[0;34m(trie)\u001b[0m\n\u001b[1;32m     10\u001b[0m             r\u001b[39m.\u001b[39mhset(child_node_key, \u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m, child_key)\n\u001b[1;32m     11\u001b[0m         dfs(child_node, child_key)\n\u001b[0;32m---> 12\u001b[0m dfs(trie\u001b[39m.\u001b[39;49mroot, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[126], line 8\u001b[0m, in \u001b[0;36mimport_trie_to_redis.<locals>.dfs\u001b[0;34m(node, node_key)\u001b[0m\n\u001b[1;32m      6\u001b[0m child_node_key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mchild_key\u001b[39m}\u001b[39;00m\u001b[39m:node\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m r\u001b[39m.\u001b[39mhset(child_node_key, \u001b[39m\"\u001b[39m\u001b[39mis_word\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(child_node\u001b[39m.\u001b[39mis_word))\n\u001b[0;32m----> 8\u001b[0m r\u001b[39m.\u001b[39;49mhset(child_node_key, \u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m, child_node\u001b[39m.\u001b[39;49mdescription)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m child_node\u001b[39m.\u001b[39mis_word:\n\u001b[1;32m     10\u001b[0m     r\u001b[39m.\u001b[39mhset(child_node_key, \u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m, child_key)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/commands/core.py:4919\u001b[0m, in \u001b[0;36mHashCommands.hset\u001b[0;34m(self, name, key, value, mapping, items)\u001b[0m\n\u001b[1;32m   4916\u001b[0m     \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4917\u001b[0m         items\u001b[39m.\u001b[39mextend(pair)\n\u001b[0;32m-> 4919\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_command(\u001b[39m\"\u001b[39;49m\u001b[39mHSET\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39m*\u001b[39;49mitems)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/client.py:1258\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m   1255\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection \u001b[39mor\u001b[39;00m pool\u001b[39m.\u001b[39mget_connection(command_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1258\u001b[0m     \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39;49mretry\u001b[39m.\u001b[39;49mcall_with_retry(\n\u001b[1;32m   1259\u001b[0m         \u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_command_parse_response(\n\u001b[1;32m   1260\u001b[0m             conn, command_name, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions\n\u001b[1;32m   1261\u001b[0m         ),\n\u001b[1;32m   1262\u001b[0m         \u001b[39mlambda\u001b[39;49;00m error: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_disconnect_raise(conn, error),\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[1;32m   1264\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection:\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/retry.py:46\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[0;34m(self, do, fail)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[39mreturn\u001b[39;00m do()\n\u001b[1;32m     47\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supported_errors \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     48\u001b[0m         failures \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/client.py:1259\u001b[0m, in \u001b[0;36mRedis.execute_command.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1255\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection \u001b[39mor\u001b[39;00m pool\u001b[39m.\u001b[39mget_connection(command_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39mretry\u001b[39m.\u001b[39mcall_with_retry(\n\u001b[0;32m-> 1259\u001b[0m         \u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_command_parse_response(\n\u001b[1;32m   1260\u001b[0m             conn, command_name, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions\n\u001b[1;32m   1261\u001b[0m         ),\n\u001b[1;32m   1262\u001b[0m         \u001b[39mlambda\u001b[39;00m error: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disconnect_raise(conn, error),\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[1;32m   1264\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection:\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/client.py:1234\u001b[0m, in \u001b[0;36mRedis._send_command_parse_response\u001b[0;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_send_command_parse_response\u001b[39m(\u001b[39mself\u001b[39m, conn, command_name, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions):\n\u001b[1;32m   1231\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[39m    Send a command and parse the response\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m     conn\u001b[39m.\u001b[39;49msend_command(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_response(conn, command_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/connection.py:916\u001b[0m, in \u001b[0;36mConnection.send_command\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    914\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pack and send a command to the Redis server\"\"\"\u001b[39;00m\n\u001b[1;32m    915\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_packed_command(\n\u001b[0;32m--> 916\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_command_packer\u001b[39m.\u001b[39;49mpack(\u001b[39m*\u001b[39;49margs),\n\u001b[1;32m    917\u001b[0m         check_health\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcheck_health\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    918\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/connection.py:558\u001b[0m, in \u001b[0;36mPythonRespSerializer.pack\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    555\u001b[0m buff \u001b[39m=\u001b[39m SYM_EMPTY\u001b[39m.\u001b[39mjoin((SYM_STAR, \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(args))\u001b[39m.\u001b[39mencode(), SYM_CRLF))\n\u001b[1;32m    557\u001b[0m buffer_cutoff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_cutoff\n\u001b[0;32m--> 558\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode, args):\n\u001b[1;32m    559\u001b[0m     \u001b[39m# to avoid large string mallocs, chunk the command into the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# output list if we're sending large values or memoryviews\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     arg_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(arg)\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    563\u001b[0m         \u001b[39mlen\u001b[39m(buff) \u001b[39m>\u001b[39m buffer_cutoff\n\u001b[1;32m    564\u001b[0m         \u001b[39mor\u001b[39;00m arg_length \u001b[39m>\u001b[39m buffer_cutoff\n\u001b[1;32m    565\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mmemoryview\u001b[39m)\n\u001b[1;32m    566\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/redis/connection.py:114\u001b[0m, in \u001b[0;36mEncoder.encode\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    112\u001b[0m     \u001b[39m# a value we don't know how to deal with. throw an error\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     typename \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m DataError(\n\u001b[1;32m    115\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid input of type: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtypename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConvert to a bytes, string, int or float first.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    119\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding_errors)\n",
      "\u001b[0;31mDataError\u001b[0m: Invalid input of type: 'NoneType'. Convert to a bytes, string, int or float first."
     ]
    }
   ],
   "source": [
    "import_trie_to_redis(trie_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def tokenizerImport(self):\n",
    "        with open('tokenizer.json') as f:\n",
    "            data = json.load(f)\n",
    "            tokenizer = tokenizer_from_json(data)\n",
    "        return tokenizer\n",
    "    \n",
    "    def modelImport(self):\n",
    "        model = load_model('model_general_1.h5')\n",
    "        return model\n",
    "        \n",
    "    def build_definition(self, seed_text, tokenizer, next_words, model, max_sequence_len):\n",
    "        res = []\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "            predicted = model.predict(token_list)\n",
    "            predicted = np.argmax(predicted, axis = 1)\n",
    "            \n",
    "            output_word = \"\"\n",
    "            for word,index in tokenizer.word_index.items():\n",
    "                if index == predicted:\n",
    "                    output_word = word\n",
    "                    break\n",
    "            res.append(output_word)\n",
    "            seed_text += \" \" + output_word\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_trie(trie_dict):\n",
    "    # ML_used = False\n",
    "    # Prompt the user to enter a search term\n",
    "    print('Enter the term for which you would like the definition')\n",
    "    search = input()\n",
    "    \n",
    "    # Use the trie data structure to perform a fuzzy search on the search term\n",
    "    search_result = list(trie_dict.fuzzy_search(search))\n",
    "    list_length = len(search_result)\n",
    "    \n",
    "    # If the search term is not found in the trie, prompt the user to define it\n",
    "    if list_length == 0:\n",
    "        print('It is not in our list, please define it yourself')\n",
    "        definition = input()\n",
    "        #fine_tune(search, definition)\n",
    "        print(f\"Thanks, I've learned the definition of '{search}'.\")\n",
    "        \n",
    "    # If the search term is found in the trie, present the user with a list of search results\n",
    "    else:\n",
    "        for i, item in enumerate(search_result):\n",
    "            print(f\"{i+1}. {item}\")\n",
    "        \n",
    "        # Prompt the user to select a search result from the list\n",
    "        print('If the desired item is in the list, type Y')\n",
    "        choice = input()\n",
    "        if choice == 'Y':\n",
    "            print('Now type the number associated to the desired term')\n",
    "            user_choice = int(input())\n",
    "            \n",
    "            # Ensure that the user's choice is a valid index in the list of search results\n",
    "            1 <= user_choice <= len(search_result)\n",
    "            selected_item = search_result[user_choice - 1]\n",
    "            print(f\"You selected: {selected_item}\")\n",
    "            \n",
    "            # Look up the definition of the selected term in the trie data structure\n",
    "            word_definition = trie_dict.search(selected_item)\n",
    "            \n",
    "            # If the term has no definition in the trie, prompt the user to define it\n",
    "            if word_definition == None:\n",
    "                print(f'No previous definition has been found, however {selected_item} is commonly referred to as:\\n ')\n",
    "                print(get_definition(selected_item))\n",
    "                print('Now you can define it yourself')\n",
    "                custom_definition = input()\n",
    "                trie_dict.insert(selected_item, custom_definition)\n",
    "                print('Thank you, I learned a new word!')\n",
    "            \n",
    "            # If the term has a definition in the trie, present the definition to the user and prompt for redefinition\n",
    "            else:\n",
    "                print(f'The definition for {selected_item} is : {word_definition}')\n",
    "                print(f'Do you like it? Type \"Y\" if so, if not you\"ll redefine it')\n",
    "                redefinition_choice = input()\n",
    "                \n",
    "                # If the user chooses to redefine the term, prompt for a new definition and update the trie\n",
    "                if redefinition_choice != 'Y':\n",
    "                    print('Type it in:')\n",
    "                    custom_definition = input()\n",
    "                    trie_dict.insert(selected_item, custom_definition)\n",
    "                    print('Thank you, I learned a new word!')\n",
    "        else:\n",
    "            print(f'Run ML model? (Type \"Y\" for yes and \"N\" for no)')\n",
    "            runChoice = input()\n",
    "            if runChoice == \"Y\":\n",
    "                print(f'\"{search}\" is not in the list, running ML model to generate definition')\n",
    "                ml_model = MLModel()\n",
    "                tokenizer = ml_model.tokenizerImport()\n",
    "                model = ml_model.modelImport()\n",
    "                res = ml_model.build_definition(search, tokenizer, 5, model, 54)\n",
    "                \n",
    "                for i in range(len(res)):\n",
    "                    print(f\"{i+1}. {res[i]}\")\n",
    "                \n",
    "                print(f'If you see a definition that you are satisfied with, select the corresponding number - else if you are not satisifed with any option, type \"N\": ')\n",
    "                mlChoice = input()\n",
    "\n",
    "                if mlChoice != 'N':\n",
    "                    trie_dict.insert(search, res[int(mlChoice)])\n",
    "                else:\n",
    "                    print('Add your own definition: ')\n",
    "                    definition_nbs = input()\n",
    "                    trie_dict.insert(search, definition_nbs)\n",
    "            else:\n",
    "                print('Add your own definition: ')\n",
    "                definition_nbs = input()\n",
    "                trie_dict.insert(search, definition_nbs)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9b4a2bb493eda419a542eae9e195fcc22a0fd830f7d7e5d4eaaa6ec7ed188b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
